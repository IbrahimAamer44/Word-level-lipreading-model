{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f426a8",
   "metadata": {},
   "source": [
    "# Lip Reading Prediction without CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "332e58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import os\n",
    "import cv2\n",
    "import pafy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from jiwer import wer\n",
    "from moviepy.editor import *\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be7bb9",
   "metadata": {},
   "source": [
    "# 1. Loading Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bdf5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6532d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important variables DEFINED IN PREPROCESSOR FILES\n",
    "SEQUENCE_LENGTH = 15\n",
    "IMAGE_HEIGHT = 50 \n",
    "IMAGE_WIDTH = 100\n",
    "CLASSES_LIST = ['ہے', 'کیسے', 'چار', 'دو', 'چھے', 'وہ', 'جی', 'کب', 'پانچھ', 'تین', 'آپ', 'نوں', 'ہاں', 'میں', 'تھا', 'ہوں', 'نہیں', 'کیوں', 'کتنے', 'ایک', 'کون', 'تھے', 'ہم', 'آٹھ', 'کونسا', 'کدھر', 'سات']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed81ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LRCN_model():\n",
    "    '''\n",
    "    This function will construct the required LRCN model.\n",
    "    Returns:\n",
    "        model: It is the required constructed LRCN model.\n",
    "    '''\n",
    "\n",
    "   # We will use a Sequential model for model construction.\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Define the Model Architecture.\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='valid',activation = 'relu'),\n",
    "                              input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "    \n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2)))) \n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='valid',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='valid',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='valid',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    #model.add(TimeDistributed(Dropout(0.25)))\n",
    "                                      \n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "                                      \n",
    "    model.add(GRU(64,return_sequences=True))\n",
    "    model.add(GRU(64))\n",
    "    \n",
    "    #model.add(Bidirectional(GRU(32)))\n",
    "    \n",
    "    model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))\n",
    "\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    # Display the models summary.\n",
    "    model.summary()\n",
    "    \n",
    "    # Return the constructed LRCN model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991f011a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 15, 48, 98, 16)   448       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 15, 24, 49, 16)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 15, 24, 49, 16)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 15, 22, 47, 32)   4640      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 15, 11, 23, 32)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 15, 11, 23, 32)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 15, 9, 21, 64)    18496     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 15, 4, 10, 64)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 15, 4, 10, 64)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 15, 2, 8, 64)     36928     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 15, 1, 4, 64)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 15, 256)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 15, 64)            61824     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 64)                24960     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 27)                1755      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,051\n",
      "Trainable params: 149,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LRCN_model = create_LRCN_model()\n",
    "# Compile the model and specify loss function, optimizer and metrics to the model.\n",
    "LRCN_model.compile(loss = 'categorical_crossentropy', optimizer=Adam(lr = 0.00001), metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "#LRCN_model.load_weights(r\"C:\\Users\\ibrah\\OneDrive\\Desktop\\Best word level predictions\\Model_1-Without-CTC-LOSS_checkpoint1_tillbatch_5.h5\")\n",
    "LRCN_model.load_weights(r\"C:\\Users\\ibrah\\OneDrive\\Desktop\\Best word level predictions\\Model_1-Without-CTC-LOSS_checkpoint1_tillbatch_9.h5\")\n",
    "#LRCN_model.load_weights('Model_1-Without-CTC-LOSS_checkpoint1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a6bd1",
   "metadata": {},
   "source": [
    "# 2. Making Prediction on Existing Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5bc2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_u = ['میں', 'آپ', 'ہم', 'وہ']\n",
    "w2_k_u = ['کیسے', 'کونسا', 'کدھر', 'کتنے']\n",
    "w3_u = ['ہوں', 'تھا', 'ہے', 'تھے']\n",
    "w4_k_u = ['جی', 'ہاں', 'نہیں']\n",
    "w5_u = ['کیوں', 'کب', 'کون']\n",
    "w6_k_u = ['ایک', 'دو', 'تین', 'چار', 'پانچھ', 'چھے', 'سات', 'آٹھ', 'نوں']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec0f9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [w1_u, w2_k_u, w3_u, w4_k_u, w5_u, w6_k_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f76fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get most likely word in a given set of words\n",
    "def get_most_likely_word(word_list, CLASSES_LIST, res):\n",
    "    \n",
    "    prob = float(0.0)\n",
    "    pred = ''\n",
    "    \n",
    "    ls = []\n",
    "\n",
    "    for i in word_list:\n",
    "        index = CLASSES_LIST.index(i)\n",
    "        tmp_prob = res[index]\n",
    "              \n",
    "        if tmp_prob >  prob:\n",
    "            prob = tmp_prob\n",
    "            pred = i\n",
    "    \n",
    "    return pred,prob\n",
    "\n",
    "#word = get_most_likely_word(w6_k_u, CLASSES_LIST, res)\n",
    "#print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900665a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "from lips import crop_lips\n",
    "import mediapipe as mp\n",
    "\n",
    "# file_path = \"..\\\\Dataset\\\\Urdu\\\\6\\\\aap_kitne_tha_han_kyun_ek\\\\_video.avi\"\n",
    "\n",
    "def predict_word_level(file_path, word_list, CLASSES_LIST, SEQUENCE_LENGTH):\n",
    "    mp_holistic = mp.solutions.holistic  # Holistic model\n",
    "    mp_drawing = mp.solutions.drawing_utils  # Drawing utilities\n",
    "\n",
    "\n",
    "    # Declare a queue to store video frames.\n",
    "    frames_queue = deque(maxlen = SEQUENCE_LENGTH)\n",
    "\n",
    "    # Initialize a variable to store the predicted action being performed in the video.\n",
    "    predicted_class_name = ''\n",
    "\n",
    "    sentence = []\n",
    "    predictions = []\n",
    "    threshold = 0.0 # Result rendered only if they are above this threshold\n",
    "\n",
    "    # Create a VideoCapture object and read from input file\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    win_size = int((total_frames - 12) / 6) \n",
    "\n",
    "    w_cnt = 0\n",
    "\n",
    "    # Progress bar\n",
    "    #f = IntProgress(min=0, max=total_frames-12) # instantiate the bar\n",
    "    #display(f) # display the bar\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video file\")\n",
    "\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    w0 = []\n",
    "    w1 = []\n",
    "    w2 = []\n",
    "    w3 = []\n",
    "    w4 = []\n",
    "    w5 = []\n",
    "\n",
    "\n",
    "    cnt = 0\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.1, min_tracking_confidence=0.1) as holistic:    \n",
    "        # Read until video is completed\n",
    "        while(cap.isOpened()):\n",
    "\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # If frame correctly read only then performing predictions\n",
    "            if ret == True:\n",
    "\n",
    "                # Cropping lips\n",
    "                cropped_image = crop_lips(frame, holistic)\n",
    "\n",
    "                # Normalizing the cropped frame\n",
    "                normalized_frame = cropped_image / 255    \n",
    "\n",
    "                # Appending the pre-processed frame into the frames list.\n",
    "                frames_queue.append(normalized_frame)\n",
    "\n",
    "                # Check if the number of frames in the queue are equal to the fixed sequence length.\n",
    "                if len(frames_queue) == SEQUENCE_LENGTH:\n",
    "\n",
    "                    # Pass the normalized frames to the model and get the predicted probabilities.\n",
    "                    res = LRCN_model.predict(np.expand_dims(frames_queue, axis = 0), verbose=0)[0]\n",
    "                    \n",
    "                    #print(CLASSES_LIST[np.argmax(res)])\n",
    "                    \n",
    "                    # Appending prediction in the Predictions List\n",
    "                    predictions.append(np.argmax(res))\n",
    "\n",
    "                    #preds.append(get_most_likely_word(word_list[0], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[1], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[2], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[3], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[4], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[5], CLASSES_LIST, res))\n",
    "                    #sentence.append(pred)\n",
    "\n",
    "                    if w_cnt < win_size:\n",
    "                        p0_w, p0_acc = get_most_likely_word(word_list[0], CLASSES_LIST, res)\n",
    "                        if p0_acc > threshold:\n",
    "                            w0.append([p0_w, p0_acc])\n",
    "\n",
    "\n",
    "\n",
    "                    if w_cnt > win_size and w_cnt < (2*win_size):\n",
    "                        p1_w, p1_acc = get_most_likely_word(word_list[1], CLASSES_LIST, res)\n",
    "                        if p1_acc > threshold:\n",
    "                            w1.append([p1_w, p1_acc])\n",
    "\n",
    "                    if w_cnt > (2*win_size) and w_cnt < (3*win_size):\n",
    "                        p2_w, p2_acc = get_most_likely_word(word_list[2], CLASSES_LIST, res)\n",
    "                        if p2_acc > threshold:\n",
    "                            w2.append([p2_w, p2_acc])\n",
    "\n",
    "                    if w_cnt > (3*win_size) and w_cnt < (4*win_size):\n",
    "                        p3_w, p3_acc = get_most_likely_word(word_list[3], CLASSES_LIST, res)\n",
    "                        if p3_acc > threshold:\n",
    "                            w3.append([p3_w, p3_acc])\n",
    "\n",
    "                    if w_cnt > (4*win_size) and w_cnt < (5*win_size):\n",
    "                        p4_w, p4_acc = get_most_likely_word(word_list[4], CLASSES_LIST, res)\n",
    "                        if p4_acc > threshold:\n",
    "                            w4.append([p4_w,p4_acc])\n",
    "\n",
    "                    if w_cnt > (5*win_size) :\n",
    "                        p5_w, p5_acc = get_most_likely_word(word_list[5], CLASSES_LIST, res)\n",
    "                        if p5_acc > threshold:\n",
    "                            w5.append([p5_w,p5_acc])\n",
    "\n",
    "\n",
    "                    w_cnt += 1\n",
    "\n",
    "                    #Progress bar variables\n",
    "                    #f.value += 1 # signal to increment the progress bar\n",
    "\n",
    "                    #print(get_most_likely_word(word_list[5], CLASSES_LIST, res))\n",
    "                    '''if np.unique(predictions[-5:])[0] == np.argmax(res):\n",
    "                        if res[np.argmax(res)] > threshold:\n",
    "                            print(CLASSES_LIST[np.argmax(res)])\n",
    "                            if len(sentence) > 0:\n",
    "                                if CLASSES_LIST[np.argmax(res)] != sentence[-1]:\n",
    "                                    sentence.append(CLASSES_LIST[np.argmax(res)])\n",
    "                            else:\n",
    "                                sentence.append(CLASSES_LIST[np.argmax(res)])\n",
    "                    '''\n",
    "\n",
    "                    if len(sentence) < 8:\n",
    "\n",
    "                        sentence.extend(np.unique(preds))\n",
    "\n",
    "\n",
    "                #print(sentence)\n",
    "\n",
    "                #cv2.putText(frame, ' '.join(sentence) , (2, 30),cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                # Display the resulting frame\n",
    "                #cv2.imshow('Frame', frame)\n",
    "\n",
    "\n",
    "            # Press Q on keyboard to exit\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            # Break the loop\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "     # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return [w0, w1, w2, w3, w4, w5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb65ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns word with highest probability in a window\n",
    "def highest_prob_word(words):\n",
    "    \n",
    "    w = ''\n",
    "    acc = 0\n",
    "    for i in words:\n",
    "        if i[1] > acc:\n",
    "            w = i[0]\n",
    "    \n",
    "    return w\n",
    "\n",
    "# Returns most frequently occuring word in a window\n",
    "def most_freq_word(words):\n",
    "    \n",
    "    tmp_list = []\n",
    "    \n",
    "    for i in words:\n",
    "        tmp_list.append(i[0])\n",
    "    \n",
    "    return max(set(tmp_list), key = tmp_list.count)\n",
    "\n",
    "# General function to parse sentence [args : prediction results, function to be used for getting predicted words]\n",
    "def parse_sentence(prediction, func):\n",
    "    \n",
    "    sen = func(prediction[0])+\" \"+func(prediction[1])+\" \"+func(prediction[2])+\" \"+func(prediction[3])+\" \"+func(prediction[4])+\" \"+func(prediction[5])\n",
    "    \n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db0e498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening video file\n"
     ]
    }
   ],
   "source": [
    "#file_path = r\"D:\\FYP Workspace\\Raw Data\\8\\aap_kitne_tha_han_kyun_ek\\_video.avi\"\n",
    "file_path = r\"C:\\Users\\ibrah\\OneDrive\\Desktop\\Docs\\7th Semester\\FYP\\Workspace 2\\Word Level Lip Reading\\Preprocessing\\Unseen_videos\\آپ_کتنے_تھا_نہیں_کیوں_نو.mp4\"\n",
    "prediction = predict_word_level(file_path, word_list, CLASSES_LIST, SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31c64cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "میں کیسے تھا ہاں کون پانچھ\n",
      "میں کیسے تھا ہاں کون سات\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(parse_sentence(prediction, most_freq_word))\n",
    "print(parse_sentence(prediction, highest_prob_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ead06f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['میں', 0.025866712],\n",
       "  ['میں', 0.026979527],\n",
       "  ['میں', 0.02805288],\n",
       "  ['میں', 0.029016558],\n",
       "  ['میں', 0.029857717],\n",
       "  ['میں', 0.03033493],\n",
       "  ['میں', 0.03013219],\n",
       "  ['میں', 0.029500723],\n",
       "  ['میں', 0.02915101],\n",
       "  ['میں', 0.028710244],\n",
       "  ['میں', 0.028442157],\n",
       "  ['میں', 0.02837359],\n",
       "  ['میں', 0.0284607],\n",
       "  ['میں', 0.028488124]],\n",
       " [['کتنے', 0.057769783],\n",
       "  ['کتنے', 0.055372745],\n",
       "  ['کتنے', 0.05331666],\n",
       "  ['کتنے', 0.052140288],\n",
       "  ['کتنے', 0.049522202],\n",
       "  ['کدھر', 0.047862984],\n",
       "  ['کدھر', 0.05155868],\n",
       "  ['کدھر', 0.056878805],\n",
       "  ['کدھر', 0.06279432],\n",
       "  ['کدھر', 0.06671741],\n",
       "  ['کیسے', 0.06756581],\n",
       "  ['کیسے', 0.06873552],\n",
       "  ['کیسے', 0.068394154]],\n",
       " [['ہے', 0.14933439],\n",
       "  ['ہے', 0.15167901],\n",
       "  ['ہے', 0.15165126],\n",
       "  ['ہے', 0.15105468],\n",
       "  ['ہے', 0.15043254],\n",
       "  ['ہے', 0.14906704],\n",
       "  ['ہے', 0.14743885],\n",
       "  ['ہے', 0.14590706],\n",
       "  ['ہے', 0.14322042],\n",
       "  ['ہے', 0.13968848],\n",
       "  ['ہے', 0.13542798],\n",
       "  ['ہے', 0.13094649],\n",
       "  ['ہے', 0.1265161]],\n",
       " [['نہیں', 0.15125707],\n",
       "  ['نہیں', 0.15090811],\n",
       "  ['نہیں', 0.15086944],\n",
       "  ['نہیں', 0.14962918],\n",
       "  ['نہیں', 0.14869858],\n",
       "  ['نہیں', 0.14949022],\n",
       "  ['نہیں', 0.1537287],\n",
       "  ['نہیں', 0.1558317],\n",
       "  ['نہیں', 0.15707098],\n",
       "  ['نہیں', 0.16184354],\n",
       "  ['نہیں', 0.16926245],\n",
       "  ['نہیں', 0.17810692],\n",
       "  ['نہیں', 0.18312088]],\n",
       " [['کب', 0.03154979],\n",
       "  ['کب', 0.03161595],\n",
       "  ['کب', 0.031015752],\n",
       "  ['کب', 0.030364325],\n",
       "  ['کب', 0.030090027],\n",
       "  ['کب', 0.03048053],\n",
       "  ['کب', 0.03101558],\n",
       "  ['کب', 0.030886972],\n",
       "  ['کب', 0.03041194],\n",
       "  ['کب', 0.029498443],\n",
       "  ['کب', 0.028062748],\n",
       "  ['کب', 0.025817052],\n",
       "  ['کب', 0.024226926]],\n",
       " [['آٹھ', 0.04038025],\n",
       "  ['آٹھ', 0.040201355],\n",
       "  ['آٹھ', 0.040090684],\n",
       "  ['آٹھ', 0.039917774],\n",
       "  ['آٹھ', 0.03987886],\n",
       "  ['آٹھ', 0.0397332],\n",
       "  ['آٹھ', 0.039555546],\n",
       "  ['آٹھ', 0.039459728],\n",
       "  ['آٹھ', 0.039217558],\n",
       "  ['آٹھ', 0.03888383],\n",
       "  ['آٹھ', 0.038683806],\n",
       "  ['آٹھ', 0.038571917],\n",
       "  ['آٹھ', 0.038552634]]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf27ba44",
   "metadata": {},
   "source": [
    "for i in prediction[2]:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3ab6b",
   "metadata": {},
   "source": [
    "# 3. Record and Predict Video\n",
    "\n",
    "### - Gathering and Defining helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc782f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "# import the opencv library\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eaeb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Mediapipe model\n",
    "mp_holistic = mp.solutions.holistic  # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils  # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "056824ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"temp_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c49e72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_word_level(filepath, word_list, CLASSES_LIST, SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7000100e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "میں کتنے تھا ہاں کب آٹھ\n",
      "میں کتنے تھا نہیں کب آٹھ\n"
     ]
    }
   ],
   "source": [
    "#On batch 5 weights\n",
    "print(parse_sentence(prediction, most_freq_word))\n",
    "print(parse_sentence(prediction, highest_prob_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ffb211b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "میں کیسے تھا ہاں کب آٹھ\n",
      "میں کیسے تھا ہاں کون آٹھ\n"
     ]
    }
   ],
   "source": [
    "#On batch 9 weights\n",
    "print(parse_sentence(prediction, most_freq_word))\n",
    "print(parse_sentence(prediction, highest_prob_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1502e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "میں کدھر تھا ہاں کب آٹھ\n",
      "میں کدھر تھا ہاں کب آٹھ\n"
     ]
    }
   ],
   "source": [
    "#On latest weights\n",
    "print(parse_sentence(prediction, most_freq_word))\n",
    "print(parse_sentence(prediction, highest_prob_word))\n",
    "\n",
    "\"\"\"\n",
    "میں کدھر تھا ہاں کب آٹھ\n",
    "میں کدھر تھا ہاں کب آٹھ\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c3175cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536e6303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['وہ', 0.042594664],\n",
       "  ['وہ', 0.040996153],\n",
       "  ['وہ', 0.03893286],\n",
       "  ['وہ', 0.040079854],\n",
       "  ['وہ', 0.039443478],\n",
       "  ['وہ', 0.03948737],\n",
       "  ['وہ', 0.040604953],\n",
       "  ['وہ', 0.04034933],\n",
       "  ['وہ', 0.040025346],\n",
       "  ['وہ', 0.040301472],\n",
       "  ['وہ', 0.03747733],\n",
       "  ['وہ', 0.032850724]],\n",
       " [['کونسا', 0.13111618],\n",
       "  ['کونسا', 0.1165776],\n",
       "  ['کونسا', 0.09973614],\n",
       "  ['کونسا', 0.07442825],\n",
       "  ['کونسا', 0.05353079],\n",
       "  ['کیسے', 0.049553864],\n",
       "  ['کتنے', 0.05043427],\n",
       "  ['کتنے', 0.05059517],\n",
       "  ['کتنے', 0.050401356],\n",
       "  ['کتنے', 0.049986657],\n",
       "  ['کتنے', 0.04930621]],\n",
       " [['تھا', 0.1235],\n",
       "  ['تھا', 0.1266356],\n",
       "  ['تھا', 0.12633795],\n",
       "  ['تھا', 0.12282128],\n",
       "  ['ہے', 0.11912547],\n",
       "  ['ہے', 0.11510526],\n",
       "  ['ہے', 0.10950241],\n",
       "  ['ہے', 0.10403517],\n",
       "  ['ہے', 0.09811872],\n",
       "  ['ہے', 0.091240436],\n",
       "  ['ہے', 0.08505084]],\n",
       " [['ہاں', 0.13626473],\n",
       "  ['ہاں', 0.120318],\n",
       "  ['نہیں', 0.09913375],\n",
       "  ['نہیں', 0.08568436],\n",
       "  ['نہیں', 0.07119999],\n",
       "  ['نہیں', 0.062424388],\n",
       "  ['نہیں', 0.06638001],\n",
       "  ['نہیں', 0.07582516],\n",
       "  ['نہیں', 0.08738724],\n",
       "  ['نہیں', 0.09933024],\n",
       "  ['ہاں', 0.11121083]],\n",
       " [['کب', 0.04262615],\n",
       "  ['کب', 0.041233327],\n",
       "  ['کب', 0.041199155],\n",
       "  ['کب', 0.039918758],\n",
       "  ['کب', 0.039104763],\n",
       "  ['کب', 0.03846597],\n",
       "  ['کب', 0.037726264],\n",
       "  ['کب', 0.037294537],\n",
       "  ['کب', 0.038084295],\n",
       "  ['کب', 0.038461912],\n",
       "  ['کب', 0.03873925]],\n",
       " [['آٹھ', 0.050393507],\n",
       "  ['آٹھ', 0.05034321],\n",
       "  ['آٹھ', 0.049891237],\n",
       "  ['آٹھ', 0.04742753],\n",
       "  ['آٹھ', 0.045692284],\n",
       "  ['آٹھ', 0.04444312],\n",
       "  ['آٹھ', 0.043710683],\n",
       "  ['آٹھ', 0.04349638],\n",
       "  ['آٹھ', 0.043480337],\n",
       "  ['آٹھ', 0.043035485],\n",
       "  ['آٹھ', 0.042729292]]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ac38bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "from Dataset import get_sentences\n",
    "import random\n",
    "\n",
    "sentences = get_sentences('..\\\\Dictionary\\\\roman_urdu_sentences.txt')\n",
    "\n",
    "\n",
    "speaker_id = 0\n",
    "\n",
    "#file_path = \"..\\\\Dataset\\\\Urdu\\\\6\\\\aap_konsa_thay_jee_kon_ek\\\\_video.avi\"\n",
    "\n",
    "x_sen = []\n",
    "y_sen_mf = []\n",
    "y_sen_hp = []\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for i in sentences:\n",
    "    \n",
    "    print(cnt)\n",
    "    \n",
    "    # Appending in actual sentence list\n",
    "    x_sen.append(i)\n",
    "    \n",
    "    sen = i.replace(' ','_')\n",
    "    \n",
    "    # Parsing filepath of the video file\n",
    "    file_path = \"D:\\\\FYP Workspace\\\\Raw Data\\\\\" + str(speaker_id) + \"\\\\\" + sen + \"\\\\_video.avi\"\n",
    "\n",
    "    # Making prediction on video and parsing sentencing\n",
    "    prediction = predict_word_level(file_path, word_list, CLASSES_LIST, SEQUENCE_LENGTH)\n",
    "    predicted_sentence = parse_sentence(prediction, highest_prob_word)\n",
    "    \n",
    "    # Appending in predicted sentence list\n",
    "    y_sen_hp.append(parse_sentence(prediction, highest_prob_word))\n",
    "    y_sen_mf.append(parse_sentence(prediction,most_freq_word))\n",
    "    \n",
    "    cnt += 1\n",
    "    \n",
    "    if cnt == 20:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7da97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get urdu dictionary sentences\n",
    "def get_urdu_sentences(path):\n",
    "    #path = '..\\\\Dictionary\\\\roman_urdu_sentences.txt'\n",
    "\n",
    "    # Using readlines()\n",
    "    file = open(path, 'r', encoding='utf-8')\n",
    "    lines = file.readlines()\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = lines[i].replace(\"\\n\", \"\")\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fe5fa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Original :  وہ کیسے ہوں جی کب ایک\n",
      "Original :  wo_kese_hoon_jee_kab_ek\n",
      "Predicted 1:  وہ کونسا ہوں نہیں کب پانچھ   0.5\n",
      "Predicted 2:  وہ کونسا ہوں نہیں کب آٹھ   0.5\n",
      "------------------------------------\n",
      "Original :  آپ کیسے ہے جی کیوں دو\n",
      "Original :  aap_kese_hai_jee_kyun_do\n",
      "Predicted 1:  میں کیسے تھا نہیں کیوں پانچھ   0.6666666666666666\n",
      "Predicted 2:  وہ کیسے تھا ہاں کیوں دو   0.5\n",
      "------------------------------------\n",
      "Original :  وہ کیسے تھا جی کب تین\n",
      "Original :  wo_kese_tha_jee_kab_theen\n",
      "Predicted 1:  وہ کونسا تھا نہیں کب پانچھ   0.5\n",
      "Predicted 2:  وہ کونسا تھے نہیں کب آٹھ   0.6666666666666666\n",
      "------------------------------------\n",
      "Original :  میں کیسے تھے جی کیوں چار\n",
      "Original :  mein_kese_thay_jee_kyun_chaar\n",
      "Predicted 1:  وہ کیسے تھا ہاں کون آٹھ   0.8333333333333334\n",
      "Predicted 2:  وہ کونسا تھا ہاں کب آٹھ   1.0\n",
      "------------------------------------\n",
      "Original :  آپ کیسے تھا جی کیوں پانچھ\n",
      "Original :  aap_kese_tha_jee_kyun_paanch\n",
      "Predicted 1:  میں کیسے تھا جی کب پانچھ   0.3333333333333333\n",
      "Predicted 2:  میں کیسے تھا نہیں کون پانچھ   0.5\n",
      "------------------------------------\n",
      "Original :  ہم کیسے ہوں جی کیوں چھے\n",
      "Original :  hum_kese_hoon_jee_kyun_chhae\n",
      "Predicted 1:  ہم کیسے ہے جی کون آٹھ   0.5\n",
      "Predicted 2:  ہم کیسے تھے جی کیوں آٹھ   0.3333333333333333\n",
      "------------------------------------\n",
      "Original :  آپ کیسے ہوں جی کیوں سات\n",
      "Original :  aap_kese_hoon_jee_kyun_saath\n",
      "Predicted 1:  وہ کتنے تھے جی کون آٹھ   0.8333333333333334\n",
      "Predicted 2:  وہ کونسا تھے جی کب آٹھ   0.8333333333333334\n",
      "------------------------------------\n",
      "Original :  آپ کیسے ہوں جی کون آٹھ\n",
      "Original :  aap_kese_hoon_jee_kon_aath\n",
      "Predicted 1:  میں کیسے ہوں جی کب پانچھ   0.5\n",
      "Predicted 2:  وہ کیسے تھے جی کون آٹھ   0.3333333333333333\n",
      "------------------------------------\n",
      "Original :  وہ کیسے تھے جی کون نوں\n",
      "Original :  wo_kese_thay_jee_kon_nau\n",
      "Predicted 1:  وہ کونسا تھا نہیں کون دو   0.6666666666666666\n",
      "Predicted 2:  وہ کونسا تھا نہیں کون دو   0.6666666666666666\n",
      "------------------------------------\n",
      "Original :  آپ کیسے تھے ہاں کون ایک\n",
      "Original :  aap_kese_thay_han_kon_ek\n",
      "Predicted 1:  وہ کیسے تھا جی کب پانچھ   0.8333333333333334\n",
      "Predicted 2:  وہ کتنے تھا نہیں کون آٹھ   0.8333333333333334\n",
      "------------------------------------\n",
      "Original :  وہ کیسے ہے ہاں کب دو\n",
      "Original :  wo_kese_hai_han_kab_do\n",
      "Predicted 1:  وہ کونسا تھا ہاں کون پانچھ   0.6666666666666666\n",
      "Predicted 2:  وہ کونسا تھا ہاں کب دو   0.3333333333333333\n",
      "------------------------------------\n",
      "Original :  میں کیسے تھے ہاں کب تین\n",
      "Original :  mein_kese_thay_han_kab_theen\n",
      "Predicted 1:  وہ کیسے تھا ہاں کب آٹھ   0.5\n",
      "Predicted 2:  وہ کونسا تھا ہاں کب آٹھ   0.6666666666666666\n",
      "------------------------------------\n",
      "Original :  آپ کیسے تھے ہاں کب چار\n",
      "Original :  aap_kese_thay_han_kab_chaar\n",
      "Predicted 1:  وہ کتنے تھا ہاں کون آٹھ   0.8333333333333334\n",
      "Predicted 2:  وہ کونسا تھا ہاں کب آٹھ   0.6666666666666666\n",
      "------------------------------------\n",
      "Original :  وہ کیسے ہے ہاں کیوں پانچھ\n",
      "Original :  wo_kese_hai_han_kyun_paanch\n",
      "Predicted 1:  وہ کونسا تھا نہیں کون پانچھ   0.6666666666666666\n",
      "Predicted 2:  وہ کونسا تھا ہاں کون آٹھ   0.6666666666666666\n",
      "------------------------------------\n",
      "Original :  وہ کیسے تھا ہاں کب چھے\n",
      "Original :  wo_kese_tha_han_kab_chhae\n",
      "Predicted 1:  وہ کونسا تھا ہاں کون پانچھ   0.5\n",
      "Predicted 2:  وہ کونسا تھا ہاں کب آٹھ   0.3333333333333333\n",
      "------------------------------------\n",
      "Original :  ہم کیسے تھے ہاں کب سات\n",
      "Original :  hum_kese_thay_han_kab_saath\n",
      "Predicted 1:  میں کیسے تھا ہاں کب پانچھ   0.5\n",
      "Predicted 2:  میں کیسے تھا ہاں کب آٹھ   0.5\n",
      "------------------------------------\n",
      "Original :  ہم کیسے ہے ہاں کب آٹھ\n",
      "Original :  hum_kese_hai_han_kab_aath\n",
      "Predicted 1:  میں کتنے تھا ہاں کب پانچھ   0.6666666666666666\n",
      "Predicted 2:  میں کتنے تھا ہاں کب پانچھ   0.6666666666666666\n",
      "------------------------------------\n",
      "Original :  ہم کیسے تھا ہاں کیوں نوں\n",
      "Original :  hum_kese_tha_han_kyun_nau\n",
      "Predicted 1:  میں کونسا تھا ہاں کون پانچھ   0.6666666666666666\n",
      "Predicted 2:  وہ کیسے تھا ہاں کب دو   0.5\n",
      "------------------------------------\n",
      "Original :  آپ کیسے تھے نہیں کیوں ایک\n",
      "Original :  aap_kese_thay_nai_kyun_ek\n",
      "Predicted 1:  میں کتنے تھا جی کب سات   1.0\n",
      "Predicted 2:  میں کتنے تھا ہاں کب آٹھ   1.0\n",
      "------------------------------------\n",
      "Original :  میں کیسے تھے نہیں کب دو\n",
      "Original :  mein_kese_thay_nai_kab_do\n",
      "Predicted 1:  میں کیسے تھا جی کیوں پانچھ   0.6666666666666666\n",
      "Predicted 2:  وہ کیسے تھا ہاں کون پانچھ   0.8333333333333334\n",
      "------------------------------------\n",
      "\n",
      "----------------------\n",
      "\n",
      "AVG WER HP :  0.6416666666666666\n",
      "AVG WER MF :  0.6166666666666667\n"
     ]
    }
   ],
   "source": [
    "# Library to calculate WER\n",
    "\n",
    "\n",
    "#print(len(x_sen))\n",
    "#print(len(y_sen))\n",
    "urdu_sen = get_urdu_sentences('..\\\\Dictionary\\\\urdu_sentences.txt')\n",
    "\n",
    "total_wer_hp = 0\n",
    "total_wer_mf = 0\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "for i in range(0, len(y_sen_mf)):\n",
    "    \n",
    "    #arg = (ref, hypothesis)\n",
    "    wer_hp = wer(urdu_sen[i], y_sen_hp[i])\n",
    "    wer_mf = wer(urdu_sen[i], y_sen_mf[i])\n",
    "    total_wer_hp += wer_hp\n",
    "    total_wer_mf += wer_mf\n",
    "    \n",
    "    print(\"Original : \",urdu_sen[i]) \n",
    "    print(\"Original : \",sentences[i]) \n",
    "    print(\"Predicted 1: \" , y_sen_hp[i],\" \",wer_hp)\n",
    "    print(\"Predicted 2: \" , y_sen_mf[i],\" \",wer_mf)\n",
    "\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"\\n----------------------\\n\")\n",
    "avg_wer_hp = total_wer_hp / len(y_sen_hp)\n",
    "avg_wer_mf = total_wer_mf / len(y_sen_mf)\n",
    "    \n",
    "print(\"AVG WER HP : \",avg_wer_hp)    \n",
    "print(\"AVG WER MF : \",avg_wer_mf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac12e1f",
   "metadata": {},
   "source": [
    "# Testing on Seen speaker with Unknown Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4183a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_urdu_sen = get_urdu_sentences('.\\\\Unseen_videos\\\\unseen_urdu_sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f261e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_path = \".\\\\unseen_videos\\\\\"\n",
    "\n",
    "# get a list of all files and directories in the directory_path\n",
    "dir_ls = os.listdir(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2e912fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unseen_urdu_sentences.txt',\n",
       " 'آپ_کتنے_تھا_نہیں_کیوں_نوں.mp4',\n",
       " 'آپ_کدھر_تھے_نہیں_کیوں_چھے.mp4',\n",
       " 'آپ_کدھر_ہے_جی_کون_چھے.mp4',\n",
       " 'آپ_کدھر_ہے_نہیں_کون_نوں.mp4',\n",
       " 'میں_کتنے_تھا_ہاں_کب_نوں.mp4',\n",
       " 'میں_کتنے_ہوں_جی_کون_چھے.mp4',\n",
       " 'میں_کتنے_ہے_ہاں_کب_چھے.mp4',\n",
       " 'میں_کدھر_تھا_جی_کیوں_نوں.mp4',\n",
       " 'وہ_کونسا_تھے_جی_کون_نوں.mp4',\n",
       " 'وہ_کونسا_تھے_نہیں_کیوں_نوں.mp4',\n",
       " 'وہ_کونسا_ہوں_ہاں_کون_نوں.mp4',\n",
       " 'وہ_کونسا_ہے_ہاں_کون_چھے.mp4',\n",
       " 'وہ_کیسے_تھا_نہیں_کون_نوں.mp4',\n",
       " 'وہ_کیسے_تھا_ہاں_کب_چھے.mp4',\n",
       " 'وہ_کیسے_تھے_جی_کون_نوں.mp4',\n",
       " 'وہ_کیسے_ہے_نہیں_کب_چھے.mp4',\n",
       " 'ہم_کتنے_ہوں_نہیں_کب_چھے.mp4',\n",
       " 'ہم_کتنے_ہے_جی_کیوں_دو.mp4',\n",
       " 'ہم_کدھر_تھا_ہاں_کیوں_دو.mp4',\n",
       " 'ہم_کدھر_تھے_ہاں_کون_چھے.mp4',\n",
       " 'ہم_کونسا_تھے_جی_کب_چھے.mp4',\n",
       " 'ہم_کونسا_ہوں_نہیں_کب_چھے.mp4',\n",
       " 'ہم_کیسے_تھا_ہاں_کیوں_دو.mp4',\n",
       " 'ہم_کیسے_ہوں_جی_کیوں_چھے.mp4']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d0a1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Unseen_videos\\ہم_کدھر_تھا_ہاں_کیوں_دو.mp4\n",
      "Original :  ہم کدھر تھا ہاں کیوں دو\n",
      "HP       : وہ کیسے تھا ہاں کون دو   0.5\n",
      "MF       : وہ کیسے تھا ہاں کون دو   0.5\n",
      ".\\Unseen_videos\\وہ_کونسا_تھے_نہیں_کیوں_نوں.mp4\n",
      "Original :  وہ کونسا تھے نہیں کیوں نوں\n",
      "HP       : وہ کونسا تھا ہاں کیوں دو   0.5\n",
      "MF       : ہم کونسا ہوں نہیں کب دو   0.6666666666666666\n",
      ".\\Unseen_videos\\ہم_کیسے_تھا_ہاں_کیوں_دو.mp4\n",
      "Original :  ہم کیسے تھا ہاں کیوں دو\n",
      "HP       : میں کیسے تھا نہیں کیوں دو   0.3333333333333333\n",
      "MF       : میں کیسے تھا ہاں کیوں دو   0.16666666666666666\n",
      ".\\Unseen_videos\\ہم_کونسا_ہوں_نہیں_کب_چھے.mp4\n",
      "Original :  ہم کونسا ہوں نہیں کب چھے\n",
      "HP       : میں کونسا ہوں نہیں کب سات   0.3333333333333333\n",
      "MF       : میں کونسا ہوں جی کب سات   0.5\n",
      ".\\Unseen_videos\\وہ_کونسا_تھے_جی_کون_نوں.mp4\n",
      "Original :  وہ کونسا تھے جی کون نوں\n",
      "HP       : وہ کونسا تھے جی کون پانچھ   0.16666666666666666\n",
      "MF       : ہم کونسا تھا نہیں کون پانچھ   0.6666666666666666\n",
      ".\\Unseen_videos\\وہ_کونسا_ہے_ہاں_کون_چھے.mp4\n",
      "Original :  وہ کونسا ہے ہاں کون چھے\n",
      "HP       : وہ کونسا تھا جی کب سات   0.6666666666666666\n",
      "MF       : ہم کونسا تھا ہاں کون آٹھ   0.5\n",
      ".\\Unseen_videos\\وہ_کیسے_تھا_ہاں_کب_چھے.mp4\n",
      "Original :  وہ کیسے تھا ہاں کب چھے\n",
      "HP       : وہ کیسے تھا ہاں کب آٹھ   0.16666666666666666\n",
      "MF       : آپ کونسا تھا ہاں کب آٹھ   0.5\n",
      ".\\Unseen_videos\\آپ_کتنے_تھا_نہیں_کیوں_نوں.mp4\n",
      "Original :  آپ کتنے تھا نہیں کیوں نوں\n",
      "HP       : میں کیسے تھا جی کون پانچھ   0.8333333333333334\n",
      "MF       : میں کیسے تھا ہاں کون پانچھ   0.8333333333333334\n",
      ".\\Unseen_videos\\میں_کدھر_تھا_جی_کیوں_نوں.mp4\n",
      "Original :  میں کدھر تھا جی کیوں نوں\n",
      "HP       : میں کیسے تھا نہیں کیوں پانچھ   0.5\n",
      "MF       : میں کیسے تھا نہیں کیوں پانچھ   0.5\n",
      ".\\Unseen_videos\\آپ_کدھر_ہے_نہیں_کون_نوں.mp4\n",
      "Original :  آپ کدھر ہے نہیں کون نوں\n",
      "HP       : میں کیسے تھا جی کیوں پانچھ   1.0\n",
      "MF       : میں کیسے تھا ہاں کون پانچھ   0.8333333333333334\n",
      ".\\Unseen_videos\\آپ_کدھر_تھے_نہیں_کیوں_چھے.mp4\n",
      "Original :  آپ کدھر تھے نہیں کیوں چھے\n",
      "HP       : میں کیسے تھا جی کب پانچھ   1.0\n",
      "MF       : میں کیسے تھا ہاں کون سات   1.0\n",
      ".\\Unseen_videos\\وہ_کونسا_ہوں_ہاں_کون_نوں.mp4\n",
      "Original :  وہ کونسا ہوں ہاں کون نوں\n",
      "HP       : وہ کونسا ہوں ہاں کون پانچھ   0.16666666666666666\n",
      "MF       : ہم کونسا ہوں ہاں کون پانچھ   0.3333333333333333\n",
      ".\\Unseen_videos\\میں_کتنے_ہے_ہاں_کب_چھے.mp4\n",
      "Original :  میں کتنے ہے ہاں کب چھے\n",
      "HP       : میں کیسے تھا ہاں کب سات   0.5\n",
      "MF       : میں کیسے تھا ہاں کب سات   0.5\n",
      ".\\Unseen_videos\\ہم_کتنے_ہوں_نہیں_کب_چھے.mp4\n",
      "Original :  ہم کتنے ہوں نہیں کب چھے\n",
      "HP       : میں کیسے ہوں نہیں کب سات   0.5\n",
      "MF       : میں کیسے تھے نہیں کب سات   0.6666666666666666\n",
      ".\\Unseen_videos\\وہ_کیسے_تھے_جی_کون_نوں.mp4\n",
      "Original :  وہ کیسے تھے جی کون نوں\n",
      "HP       : وہ کیسے تھا جی کون پانچھ   0.3333333333333333\n",
      "MF       : میں کونسا تھا نہیں کون پانچھ   0.8333333333333334\n",
      ".\\Unseen_videos\\ہم_کدھر_تھے_ہاں_کون_چھے.mp4\n",
      "Original :  ہم کدھر تھے ہاں کون چھے\n",
      "HP       : میں کیسے تھا جی کب پانچھ   1.0\n",
      "MF       : میں کیسے تھا ہاں کب سات   0.8333333333333334\n",
      ".\\Unseen_videos\\ہم_کونسا_تھے_جی_کب_چھے.mp4\n",
      "Original :  ہم کونسا تھے جی کب چھے\n",
      "HP       : آپ کونسا تھا نہیں کب پانچھ   0.6666666666666666\n",
      "MF       : میں کونسا تھا نہیں کب سات   0.6666666666666666\n",
      ".\\Unseen_videos\\میں_کتنے_ہوں_جی_کون_چھے.mp4\n",
      "Original :  میں کتنے ہوں جی کون چھے\n",
      "HP       : میں کیسے تھے جی کب پانچھ   0.6666666666666666\n",
      "MF       : میں کیسے ہوں جی کب پانچھ   0.5\n",
      ".\\Unseen_videos\\وہ_کیسے_ہے_نہیں_کب_چھے.mp4\n",
      "Original :  وہ کیسے ہے نہیں کب چھے\n",
      "HP       : وہ کیسے تھا نہیں کب پانچھ   0.3333333333333333\n",
      "MF       : ہم کونسا تھا نہیں کب سات   0.6666666666666666\n",
      ".\\Unseen_videos\\آپ_کدھر_ہے_جی_کون_چھے.mp4\n",
      "Original :  آپ کدھر ہے جی کون چھے\n",
      "HP       : میں کیسے تھے جی کب پانچھ   0.8333333333333334\n",
      "MF       : میں کیسے تھا جی کب سات   0.8333333333333334\n",
      ".\\Unseen_videos\\ہم_کتنے_ہے_جی_کیوں_دو.mp4\n",
      "Original :  ہم کتنے ہے جی کیوں دو\n",
      "HP       : میں کیسے تھا جی کیوں پانچھ   0.6666666666666666\n",
      "MF       : میں کیسے تھا نہیں کیوں پانچھ   0.8333333333333334\n",
      ".\\Unseen_videos\\ہم_کیسے_ہوں_جی_کیوں_چھے.mp4\n",
      "Original :  ہم کیسے ہوں جی کیوں چھے\n",
      "HP       : میں کیسے ہوں نہیں کب سات   0.6666666666666666\n",
      "MF       : میں کیسے ہوں نہیں کون سات   0.6666666666666666\n",
      ".\\Unseen_videos\\میں_کتنے_تھا_ہاں_کب_نوں.mp4\n",
      "Original :  میں کتنے تھا ہاں کب نوں\n",
      "HP       : میں کیسے تھا نہیں کون پانچھ   0.6666666666666666\n",
      "MF       : میں کیسے تھا ہاں کون پانچھ   0.5\n",
      ".\\Unseen_videos\\وہ_کیسے_تھا_نہیں_کون_نوں.mp4\n",
      "Original :  وہ کیسے تھا نہیں کون نوں\n",
      "HP       : وہ کیسے تھا ہاں کون پانچھ   0.3333333333333333\n",
      "MF       : ہم کونسا تھا ہاں کون دو   0.6666666666666666\n",
      "Avg WER HP :  0.5555555555555555\n",
      "Avg WER MF :  0.6319444444444444\n"
     ]
    }
   ],
   "source": [
    "#prediction on each video\n",
    "\n",
    "avg_wer_hp = 0\n",
    "avg_wer_mf = 0\n",
    "for x in unseen_urdu_sen:\n",
    "    filepath = \".\\\\Unseen_videos\\\\\" + x.replace(\" \", \"_\") + \".mp4\"\n",
    "    print(filepath)\n",
    "    prediction = predict_word_level(filepath, word_list, CLASSES_LIST, SEQUENCE_LENGTH)\n",
    "    hp = parse_sentence(prediction, highest_prob_word)\n",
    "    mf = parse_sentence(prediction, most_freq_word)\n",
    "    \n",
    "    print(\"Original : \",x)\n",
    "\n",
    "    wer_hp = wer(x, hp)\n",
    "    wer_mf = wer(x, mf)\n",
    "    print(\"HP       :\",hp,\" \",wer_hp)\n",
    "    print(\"MF       :\",mf,\" \",wer_mf)\n",
    "    \n",
    "    avg_wer_hp += wer_hp\n",
    "    avg_wer_mf += wer_mf\n",
    "\n",
    "print(\"Avg WER HP : \", avg_wer_hp/len(unseen_urdu_sen))\n",
    "print(\"Avg WER MF : \", avg_wer_mf/len(unseen_urdu_sen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e740f1",
   "metadata": {},
   "source": [
    "## Test Results:\n",
    "### 1. Seen speaker seen sentence: WER    = 0.61\n",
    "### 2. Unseen speaker seen sentence WER = 0.65\n",
    "### 2. Seen speaker unseen sentence WER = 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c0f8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1684174810.2622097"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7d5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
