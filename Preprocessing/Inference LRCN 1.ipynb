{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f426a8",
   "metadata": {},
   "source": [
    "# Lip Reading Prediction without CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332e58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import os\n",
    "import cv2\n",
    "import pafy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from moviepy.editor import *\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be7bb9",
   "metadata": {},
   "source": [
    "# 1. Loading Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bdf5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6532d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important variables DEFINED IN PREPROCESSOR FILES\n",
    "SEQUENCE_LENGTH = 15\n",
    "IMAGE_HEIGHT = 50 \n",
    "IMAGE_WIDTH = 100\n",
    "CLASSES_LIST = ['ہے', 'کیسے', 'چار', 'دو', 'چھ', 'وہ', 'جی', 'کب', 'پانچھ', 'تین', 'آپ', 'نو', 'ہاں', 'میں', 'تھا', 'ہوں', 'نہیں', 'کیوں', 'کتنے', 'ایک', 'کون', 'تھے', 'ہم', 'آٹھ', 'کونسا', 'کدھر', 'سات']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed81ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LRCN_model():\n",
    "    '''\n",
    "    This function will construct the required LRCN model.\n",
    "    Returns:\n",
    "        model: It is the required constructed LRCN model.\n",
    "    '''\n",
    "\n",
    "   # We will use a Sequential model for model construction.\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Define the Model Architecture.\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='valid',activation = 'relu'),\n",
    "                              input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "    \n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2)))) \n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='valid',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='valid',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='valid',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    #model.add(TimeDistributed(Dropout(0.25)))\n",
    "                                      \n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "                                      \n",
    "    #model.add(LSTM(32))\n",
    "    gru_size = 128\n",
    "    GRU_layer = GRU(gru_size, return_sequences=True, name='lstm1')\n",
    "    model.add(Bidirectional(GRU(gru_size, return_sequences=True, name='lstm1')))\n",
    "    model.add(Bidirectional(GRU(gru_size, name='lstm1')))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    # Display the models summary.\n",
    "    # Return the constructed LRCN model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991f011a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 7 layers, found 5 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Compile the model and specify loss function, optimizer and metrics to the model.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m LRCN_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mAdam(lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00001\u001b[39m), metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m \u001b[43mLRCN_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNew_model_GRU_BEST-LOSS_batchid_16valloss_7.28.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\hdf5_format.py:817\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    815\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m filtered_layer_names\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_layers):\n\u001b[1;32m--> 817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer count mismatch when loading weights from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    819\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved layers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    821\u001b[0m     )\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;66;03m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[0;32m    825\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 7 layers, found 5 saved layers."
     ]
    }
   ],
   "source": [
    "LRCN_model = create_LRCN_model()\n",
    "# Compile the model and specify loss function, optimizer and metrics to the model.\n",
    "LRCN_model.compile(loss = 'categorical_crossentropy', optimizer=Adam(lr = 0.00001), metrics = [\"accuracy\"])\n",
    "\n",
    "LRCN_model.load_weights(\"Model_without_ctc_0.lr_0-00001_batch_0-18.h5\"))\n",
    "#LRCN_model.load_weights(\"Model_without_ctc_0.lr_0-00001_batch_0-19_a26.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a6bd1",
   "metadata": {},
   "source": [
    "# 2. Making Prediction on Existing Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_u = ['میں', 'آپ', 'ہم', 'وہ']\n",
    "w2_k_u = ['کیسے', 'کونسا', 'کدھر', 'کتنے']\n",
    "w3_u = ['ہوں', 'تھا', 'ہے', 'تھے']\n",
    "w4_k_u = ['جی', 'ہاں', 'نہیں']\n",
    "w5_u = ['کیوں', 'کب', 'کون']\n",
    "w6_k_u = ['ایک', 'دو', 'تین', 'چار', 'پانچھ', 'چھ', 'سات', 'آٹھ', 'نو']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [w1_u, w2_k_u, w3_u, w4_k_u, w5_u, w6_k_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f76fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get most likely word in a given set of words\n",
    "def get_most_likely_word(word_list, CLASSES_LIST, res):\n",
    "    \n",
    "    prob = float(0.0)\n",
    "    pred = ''\n",
    "    \n",
    "    ls = []\n",
    "\n",
    "    for i in word_list:\n",
    "        index = CLASSES_LIST.index(i)\n",
    "        tmp_prob = res[index]\n",
    "              \n",
    "        if tmp_prob >  prob:\n",
    "            prob = tmp_prob\n",
    "            pred = i\n",
    "    \n",
    "    return pred,prob\n",
    "\n",
    "#word = get_most_likely_word(w6_k_u, CLASSES_LIST, res)\n",
    "#print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900665a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "from lips import crop_lips\n",
    "import mediapipe as mp\n",
    "\n",
    "# file_path = \"..\\\\Dataset\\\\Urdu\\\\6\\\\aap_kitne_tha_han_kyun_ek\\\\_video.avi\"\n",
    "\n",
    "def predict_word_level(file_path, word_list, CLASSES_LIST, SEQUENCE_LENGTH):\n",
    "    mp_holistic = mp.solutions.holistic  # Holistic model\n",
    "    mp_drawing = mp.solutions.drawing_utils  # Drawing utilities\n",
    "\n",
    "\n",
    "    # Declare a queue to store video frames.\n",
    "    frames_queue = deque(maxlen = SEQUENCE_LENGTH)\n",
    "\n",
    "    # Initialize a variable to store the predicted action being performed in the video.\n",
    "    predicted_class_name = ''\n",
    "\n",
    "    sentence = []\n",
    "    predictions = []\n",
    "    threshold = 0.0 # Result rendered only if they are above this threshold\n",
    "\n",
    "    # Create a VideoCapture object and read from input file\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    win_size = int((total_frames - 12) / 6) \n",
    "\n",
    "    w_cnt = 0\n",
    "\n",
    "    # Progress bar\n",
    "    #f = IntProgress(min=0, max=total_frames-12) # instantiate the bar\n",
    "    #display(f) # display the bar\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video file\")\n",
    "\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    w0 = []\n",
    "    w1 = []\n",
    "    w2 = []\n",
    "    w3 = []\n",
    "    w4 = []\n",
    "    w5 = []\n",
    "\n",
    "\n",
    "    cnt = 0\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.1, min_tracking_confidence=0.1) as holistic:    \n",
    "        # Read until video is completed\n",
    "        while(cap.isOpened()):\n",
    "\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # If frame correctly read only then performing predictions\n",
    "            if ret == True:\n",
    "\n",
    "                # Cropping lips\n",
    "                cropped_image = crop_lips(frame, holistic)\n",
    "\n",
    "                # Normalizing the cropped frame\n",
    "                normalized_frame = cropped_image / 255    \n",
    "\n",
    "                # Appending the pre-processed frame into the frames list.\n",
    "                frames_queue.append(normalized_frame)\n",
    "\n",
    "                # Check if the number of frames in the queue are equal to the fixed sequence length.\n",
    "                if len(frames_queue) == SEQUENCE_LENGTH:\n",
    "\n",
    "                    # Pass the normalized frames to the model and get the predicted probabilities.\n",
    "                    res = LRCN_model.predict(np.expand_dims(frames_queue, axis = 0), verbose=0)[0]\n",
    "                    \n",
    "                    print(CLASSES_LIST[np.argmax(res)])\n",
    "                    \n",
    "                    # Appending prediction in the Predictions List\n",
    "                    predictions.append(np.argmax(res))\n",
    "\n",
    "                    #preds.append(get_most_likely_word(word_list[0], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[1], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[2], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[3], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[4], CLASSES_LIST, res))\n",
    "                    #preds.append(get_most_likely_word(word_list[5], CLASSES_LIST, res))\n",
    "                    #sentence.append(pred)\n",
    "\n",
    "                    if w_cnt < win_size:\n",
    "                        p0_w, p0_acc = get_most_likely_word(word_list[0], CLASSES_LIST, res)\n",
    "                        if p0_acc > threshold:\n",
    "                            w0.append([p0_w, p0_acc])\n",
    "\n",
    "\n",
    "\n",
    "                    if w_cnt > win_size and w_cnt < (2*win_size):\n",
    "                        p1_w, p1_acc = get_most_likely_word(word_list[1], CLASSES_LIST, res)\n",
    "                        if p1_acc > threshold:\n",
    "                            w1.append([p1_w, p1_acc])\n",
    "\n",
    "                    if w_cnt > (2*win_size) and w_cnt < (3*win_size):\n",
    "                        p2_w, p2_acc = get_most_likely_word(word_list[2], CLASSES_LIST, res)\n",
    "                        if p2_acc > threshold:\n",
    "                            w2.append([p2_w, p2_acc])\n",
    "\n",
    "                    if w_cnt > (3*win_size) and w_cnt < (4*win_size):\n",
    "                        p3_w, p3_acc = get_most_likely_word(word_list[3], CLASSES_LIST, res)\n",
    "                        if p3_acc > threshold:\n",
    "                            w3.append([p3_w, p3_acc])\n",
    "\n",
    "                    if w_cnt > (4*win_size) and w_cnt < (5*win_size):\n",
    "                        p4_w, p4_acc = get_most_likely_word(word_list[4], CLASSES_LIST, res)\n",
    "                        if p4_acc > threshold:\n",
    "                            w4.append([p4_w,p4_acc])\n",
    "\n",
    "                    if w_cnt > (5*win_size) :\n",
    "                        p5_w, p5_acc = get_most_likely_word(word_list[5], CLASSES_LIST, res)\n",
    "                        if p5_acc > threshold:\n",
    "                            w5.append([p5_w,p5_acc])\n",
    "\n",
    "\n",
    "                    w_cnt += 1\n",
    "\n",
    "                    #Progress bar variables\n",
    "                    #f.value += 1 # signal to increment the progress bar\n",
    "\n",
    "                    #print(get_most_likely_word(word_list[5], CLASSES_LIST, res))\n",
    "                    '''if np.unique(predictions[-5:])[0] == np.argmax(res):\n",
    "                        if res[np.argmax(res)] > threshold:\n",
    "                            print(CLASSES_LIST[np.argmax(res)])\n",
    "                            if len(sentence) > 0:\n",
    "                                if CLASSES_LIST[np.argmax(res)] != sentence[-1]:\n",
    "                                    sentence.append(CLASSES_LIST[np.argmax(res)])\n",
    "                            else:\n",
    "                                sentence.append(CLASSES_LIST[np.argmax(res)])\n",
    "                    '''\n",
    "\n",
    "                    if len(sentence) < 8:\n",
    "\n",
    "                        sentence.extend(np.unique(preds))\n",
    "\n",
    "\n",
    "                #print(sentence)\n",
    "\n",
    "                #cv2.putText(frame, ' '.join(sentence) , (2, 30),cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                # Display the resulting frame\n",
    "                #cv2.imshow('Frame', frame)\n",
    "\n",
    "\n",
    "            # Press Q on keyboard to exit\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            # Break the loop\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "     # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return [w0, w1, w2, w3, w4, w5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\FYP Workspace\\Raw Data\\0\\wo_kese_tha_han_kab_chhae\\_video.avi\"\n",
    "\n",
    "prediction = predict_word_level(file_path, word_list, CLASSES_LIST, SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns word with highest probability in a window\n",
    "def highest_prob_word(words):\n",
    "    \n",
    "    w = ''\n",
    "    acc = 0\n",
    "    for i in words:\n",
    "        if i[1] > acc:\n",
    "            w = i[0]\n",
    "    \n",
    "    return w\n",
    "\n",
    "# Returns most frequently occuring word in a window\n",
    "def most_freq_word(words):\n",
    "    \n",
    "    tmp_list = []\n",
    "    \n",
    "    for i in words:\n",
    "        tmp_list.append(i[0])\n",
    "    \n",
    "    return max(set(tmp_list), key = tmp_list.count)\n",
    "\n",
    "# General function to parse sentence [args : prediction results, function to be used for getting predicted words]\n",
    "def parse_sentence(prediction, func):\n",
    "    \n",
    "    sen = func(prediction[0])+\" \"+func(prediction[1])+\" \"+func(prediction[2])+\" \"+func(prediction[3])+\" \"+func(prediction[4])+\" \"+func(prediction[5])\n",
    "    \n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(parse_sentence(prediction, most_freq_word))\n",
    "#print(parse_sentence(prediction, highest_prob_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec6c0d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['وہ', 0.0003135272],\n",
       "  ['وہ', 0.0003075806],\n",
       "  ['وہ', 0.00029801187],\n",
       "  ['وہ', 0.00030042834],\n",
       "  ['وہ', 0.0003055214],\n",
       "  ['وہ', 0.0002911442],\n",
       "  ['وہ', 0.0002905727],\n",
       "  ['وہ', 0.00028994022],\n",
       "  ['وہ', 0.0002800187],\n",
       "  ['وہ', 0.00028508995],\n",
       "  ['وہ', 0.00029535138],\n",
       "  ['وہ', 0.00030491402],\n",
       "  ['وہ', 0.00030268246],\n",
       "  ['وہ', 0.00030134275]],\n",
       " [['کونسا', 0.0021174792],\n",
       "  ['کونسا', 0.00226972],\n",
       "  ['کونسا', 0.0022969807],\n",
       "  ['کونسا', 0.0023301952],\n",
       "  ['کونسا', 0.0023471767],\n",
       "  ['کونسا', 0.002334324],\n",
       "  ['کونسا', 0.0024401324],\n",
       "  ['کونسا', 0.0025586458],\n",
       "  ['کونسا', 0.0025960158],\n",
       "  ['کونسا', 0.002506506],\n",
       "  ['کونسا', 0.0022066436],\n",
       "  ['کونسا', 0.0019777264],\n",
       "  ['کونسا', 0.0019186819]],\n",
       " [['ہوں', 0.03882281],\n",
       "  ['ہوں', 0.03821545],\n",
       "  ['ہوں', 0.037633277],\n",
       "  ['ہوں', 0.03628597],\n",
       "  ['ہوں', 0.037882246],\n",
       "  ['ہوں', 0.04098809],\n",
       "  ['ہوں', 0.042226944],\n",
       "  ['ہوں', 0.042036325],\n",
       "  ['ہوں', 0.03707954],\n",
       "  ['ہوں', 0.03031575],\n",
       "  ['ہوں', 0.027466035],\n",
       "  ['ہوں', 0.02514671],\n",
       "  ['ہوں', 0.023838667]],\n",
       " [['جی', 0.17052384],\n",
       "  ['جی', 0.16378407],\n",
       "  ['جی', 0.1596076],\n",
       "  ['جی', 0.16434717],\n",
       "  ['جی', 0.16507751],\n",
       "  ['جی', 0.16549604],\n",
       "  ['جی', 0.1490601],\n",
       "  ['جی', 0.12276132],\n",
       "  ['جی', 0.099134654],\n",
       "  ['جی', 0.08417584],\n",
       "  ['جی', 0.08387968],\n",
       "  ['جی', 0.084406],\n",
       "  ['جی', 0.085495725]],\n",
       " [['کیوں', 0.168892],\n",
       "  ['کیوں', 0.16351649],\n",
       "  ['کیوں', 0.16122837],\n",
       "  ['کیوں', 0.16215901],\n",
       "  ['کیوں', 0.160396],\n",
       "  ['کیوں', 0.16313319],\n",
       "  ['کیوں', 0.16567491],\n",
       "  ['کیوں', 0.1684559],\n",
       "  ['کیوں', 0.1715968],\n",
       "  ['کیوں', 0.17620452],\n",
       "  ['کیوں', 0.17899035],\n",
       "  ['کیوں', 0.182287],\n",
       "  ['کیوں', 0.18834668]],\n",
       " [['دو', 0.19464435],\n",
       "  ['دو', 0.18244806],\n",
       "  ['دو', 0.17394638],\n",
       "  ['دو', 0.1656021],\n",
       "  ['دو', 0.15918963],\n",
       "  ['دو', 0.15045102],\n",
       "  ['دو', 0.14309138],\n",
       "  ['دو', 0.13450955],\n",
       "  ['دو', 0.124837704],\n",
       "  ['دو', 0.11734051],\n",
       "  ['دو', 0.11177777],\n",
       "  ['دو', 0.1089385]]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ead06f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['وہ', 0.00030752964],\n",
       "  ['وہ', 0.00030346695],\n",
       "  ['وہ', 0.00030106676],\n",
       "  ['وہ', 0.00030189828],\n",
       "  ['وہ', 0.00030023133],\n",
       "  ['وہ', 0.00029923843],\n",
       "  ['وہ', 0.00030286593],\n",
       "  ['وہ', 0.0002879529],\n",
       "  ['وہ', 0.00029021432],\n",
       "  ['وہ', 0.00029006423],\n",
       "  ['وہ', 0.00027735782],\n",
       "  ['وہ', 0.00026087312],\n",
       "  ['وہ', 0.00026042463],\n",
       "  ['وہ', 0.00024922693]],\n",
       " [['کونسا', 0.0019243342],\n",
       "  ['کونسا', 0.0018881434],\n",
       "  ['کونسا', 0.0018806419],\n",
       "  ['کونسا', 0.0018293484],\n",
       "  ['کونسا', 0.0018960196],\n",
       "  ['کونسا', 0.0019842228],\n",
       "  ['کونسا', 0.002002617],\n",
       "  ['کونسا', 0.0018724068],\n",
       "  ['کونسا', 0.0018470136],\n",
       "  ['کونسا', 0.0018377311],\n",
       "  ['کونسا', 0.001925882],\n",
       "  ['کونسا', 0.0019275012],\n",
       "  ['کونسا', 0.0019942264]],\n",
       " [['ہوں', 0.08729195],\n",
       "  ['ہوں', 0.09059428],\n",
       "  ['ہوں', 0.088176526],\n",
       "  ['ہوں', 0.081180714],\n",
       "  ['ہوں', 0.06671865],\n",
       "  ['ہوں', 0.056790102],\n",
       "  ['ہوں', 0.05528664],\n",
       "  ['ہوں', 0.052246273],\n",
       "  ['ہوں', 0.05341279],\n",
       "  ['ہوں', 0.053130873],\n",
       "  ['ہوں', 0.051384963],\n",
       "  ['ہوں', 0.050020188],\n",
       "  ['ہوں', 0.049260974]],\n",
       " [['جی', 0.23313165],\n",
       "  ['جی', 0.22382951],\n",
       "  ['جی', 0.21209547],\n",
       "  ['جی', 0.199075],\n",
       "  ['جی', 0.19385874],\n",
       "  ['جی', 0.18576634],\n",
       "  ['جی', 0.18448672],\n",
       "  ['جی', 0.18296123],\n",
       "  ['جی', 0.1809411],\n",
       "  ['جی', 0.17845576],\n",
       "  ['جی', 0.18771926],\n",
       "  ['جی', 0.18843491],\n",
       "  ['جی', 0.1867148]],\n",
       " [['کون', 0.14399274],\n",
       "  ['کون', 0.1330265],\n",
       "  ['کون', 0.12788436],\n",
       "  ['کون', 0.12522987],\n",
       "  ['کیوں', 0.12388432],\n",
       "  ['کون', 0.12259342],\n",
       "  ['کیوں', 0.12163346],\n",
       "  ['کیوں', 0.13210262],\n",
       "  ['کیوں', 0.1544806],\n",
       "  ['کیوں', 0.18645978],\n",
       "  ['کیوں', 0.1982044],\n",
       "  ['کیوں', 0.19510125],\n",
       "  ['کیوں', 0.18112679]],\n",
       " [['دو', 0.1306861],\n",
       "  ['دو', 0.13892753],\n",
       "  ['دو', 0.12277412],\n",
       "  ['دو', 0.118364826],\n",
       "  ['دو', 0.10786093],\n",
       "  ['دو', 0.09843721],\n",
       "  ['دو', 0.09419704],\n",
       "  ['دو', 0.085780606],\n",
       "  ['دو', 0.082876906],\n",
       "  ['دو', 0.08046845],\n",
       "  ['دو', 0.076934725]]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf27ba44",
   "metadata": {},
   "source": [
    "for i in prediction[2]:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3ab6b",
   "metadata": {},
   "source": [
    "# 3. Record and Predict Video\n",
    "\n",
    "### - Gathering and Defining helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc782f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "# import the opencv library\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eaeb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Mediapipe model\n",
    "mp_holistic = mp.solutions.holistic  # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils  # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc451ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Function to record simple video of 4 seconds\n",
    "# Args(camera_index; 1 = PC webcam, 1 = USB cam)\n",
    "def record_vid(cam_index = 0):\n",
    "    \n",
    "    # Set the video capture device (webcam)\n",
    "    cap = cv2.VideoCapture(cam_index)\n",
    "\n",
    "    width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    # Recording at 25 fps with Camera's original resolution\n",
    "    out = cv2.VideoWriter('output.mp4',fourcc, 25.0, (width,height))\n",
    "\n",
    "    # Set the duration of the video capture (in seconds)\n",
    "    duration = 4\n",
    "\n",
    "    # Capture frames for the specified duration\n",
    "    start_time = cv2.getTickCount()\n",
    "    frame_cnt = 0\n",
    "    while(int((cv2.getTickCount() - start_time)/cv2.getTickFrequency() * 1000) < duration*1000):\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret==True:\n",
    "            # Show the frame\n",
    "            cv2.imshow('frame',frame)\n",
    "            # Write the frame to the output file\n",
    "            out.write(frame)\n",
    "            frame_cnt += 1\n",
    "            # Wait for a key press to exit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            if frame_cnt == 86:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Release the video capture device and the output file\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb8218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing image and model to the function\n",
    "def mediapipe_detection(image, model):\n",
    "    # Converting frame from BGR to RGB because model works on RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Color conversion (BGR to RGB)\n",
    "    \n",
    "    image.flags.writeable = False # Image not writeable anymore\n",
    "    \n",
    "    results = model.process(image)# Making prediction\n",
    "    \n",
    "    image.flags.writeable = True # Image is now writeable\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # Color conversion (RGB to BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34c9b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_lips(image, results):\n",
    "    image_height, image_width, c = image.shape\n",
    "\n",
    "    #IMPORTANT VARIABLES\n",
    "    # Defining width and height of resized frame\n",
    "    width = 100\n",
    "    height = 50\n",
    "\n",
    "    # If no lips get detected by mediapipe then exception will be thrown\n",
    "    try:        \n",
    "        \n",
    "        # NORAMALIZING POSITIONS OF LANDMARKS(Two lines below taken from\n",
    "        x_px1 = min(math.floor(results.face_landmarks.landmark[212].x * image_width), image_width - 1)\n",
    "        x_px2 = min(math.floor(results.face_landmarks.landmark[432].x * image_width), image_width - 1)\n",
    "        y_px1 = min(math.floor(results.face_landmarks.landmark[94].y * image_height), image_height - 1)\n",
    "        y_px2 = min(math.floor(results.face_landmarks.landmark[200].y * image_height), image_height - 1)\n",
    "        \n",
    "        # Padding the image\n",
    "        pad = 0.05\n",
    "        \n",
    "\n",
    "        a = math.floor(x_px1 * (1 - pad))\n",
    "        b = math.floor(x_px2 * (1 + pad))\n",
    "        c = math.floor(y_px1 * (1 - pad))\n",
    "        d = math.floor(y_px2 * (1 + pad))\n",
    "        \n",
    "        #print(\"X = \",x_px1,\" \",x_px2)\n",
    "        #print(\"AB= \",a, \" \",b)\n",
    "        #print(\"Y = \",y_px1,\" \",y_px2)\n",
    "        #print(\"CD= \",c,\" \",d)\n",
    "        \n",
    "        # Cropping an image\n",
    "        #cropped_image = image[y_px1:y_px2, x_px1:x_px2]\n",
    "        cropped_image = image[c:d, a:b]\n",
    "\n",
    "        # Resizing the cropped image to Fixed resolution i.e. 300*150\n",
    "        dim = (width, height)\n",
    "\n",
    "        resized = cv2.resize(cropped_image, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    except:\n",
    "        # If no lips detected plain black frame will be returned\n",
    "        resized = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc64a3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "056824ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"temp_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c49e72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_word_level(filepath, word_list, CLASSES_LIST, SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1502e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "آپ کتنے تھا ہاں کون آٹھ\n",
      "آپ کتنے تھا ہاں کون آٹھ\n"
     ]
    }
   ],
   "source": [
    "print(parse_sentence(prediction, most_freq_word))\n",
    "print(parse_sentence(prediction, highest_prob_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "536e6303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261],\n",
       "  ['آپ', 0.13459261]],\n",
       " [['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556],\n",
       "  ['کتنے', 0.057291556]],\n",
       " [['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636],\n",
       "  ['تھا', 0.02471636]],\n",
       " [['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577],\n",
       "  ['ہاں', 0.05466577]],\n",
       " [['کون', 0.07838469],\n",
       "  ['کون', 0.07838469],\n",
       "  ['کون', 0.07838469],\n",
       "  ['کون', 0.07838469],\n",
       "  ['کون', 0.07838469],\n",
       "  ['کون', 0.07838469],\n",
       "  ['کون', 0.07838469],\n",
       "  ['کون', 0.07838469],\n",
       "  ['کون', 0.07838469],\n",
       "  ['کون', 0.07838469],\n",
       "  ['کون', 0.07838469]],\n",
       " [['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386],\n",
       "  ['آٹھ', 0.043546386]]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31ac38bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from Dataset import get_sentences\n",
    "\n",
    "sentences = get_sentences('..\\\\Dictionary\\\\roman_urdu_sentences.txt')\n",
    "\n",
    "speaker_id = 18\n",
    "\n",
    "#file_path = \"..\\\\Dataset\\\\Urdu\\\\6\\\\aap_konsa_thay_jee_kon_ek\\\\_video.avi\"\n",
    "\n",
    "x_sen = []\n",
    "y_sen = []\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for i in sentences:\n",
    "    \n",
    "    print(cnt)\n",
    "    \n",
    "    # Appending in actual sentence list\n",
    "    x_sen.append(i)\n",
    "    \n",
    "    sen = i.replace(' ','_')\n",
    "    \n",
    "    # Parsing filepath of the video file\n",
    "    file_path = \"D:\\\\FYP Workspace\\\\Raw Data\\\\\" + str(speaker_id) + \"\\\\\" + sen + \"\\\\_video.avi\"\n",
    "\n",
    "    # Making prediction on video and parsing sentencing\n",
    "    prediction = predict_word_level(file_path, word_list, CLASSES_LIST, SEQUENCE_LENGTH)\n",
    "    predicted_sentence = parse_sentence(prediction, highest_prob_word)\n",
    "    \n",
    "    # Appending in predicted sentence list\n",
    "    y_sen.append(predicted_sentence)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "    if cnt==4:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7da97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get urdu dictionary sentences\n",
    "def get_urdu_sentences(path):\n",
    "    #path = '..\\\\Dictionary\\\\roman_urdu_sentences.txt'\n",
    "\n",
    "    # Using readlines()\n",
    "    file = open(path, 'r', encoding='utf-8')\n",
    "    lines = file.readlines()\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = lines[i].replace(\"\\n\", \"\")\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fe5fa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original :  وہ کیسے ہوں جی کب ایک\n",
      "Predicted :  آپ کتنے تھا ہاں کون آٹھ\n",
      "------------------------------------\n",
      "Original :  آپ کیسے ہے جی کیوں دو\n",
      "Predicted :  آپ کتنے تھا ہاں کون آٹھ\n",
      "------------------------------------\n",
      "Original :  وہ کیسے تھا جی کب تین\n",
      "Predicted :  آپ کتنے تھا ہاں کون آٹھ\n",
      "------------------------------------\n",
      "Original :  میں کیسے تھے جی کیوں چار\n",
      "Predicted :  آپ کتنے تھا ہاں کون آٹھ\n",
      "------------------------------------\n",
      "Original :  آپ کیسے تھا جی کیوں پانچھ\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(urdu_sen)):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal : \u001b[39m\u001b[38;5;124m\"\u001b[39m,urdu_sen[i]) \n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted : \u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[43my_sen\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#arg = (ref, hypothesis)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Library to calculate WER\n",
    "from jiwer import wer\n",
    "\n",
    "#print(len(x_sen))\n",
    "#print(len(y_sen))\n",
    "urdu_sen = get_urdu_sentences('..\\\\Dictionary\\\\urdu_sentences.txt')\n",
    "\n",
    "total_wer = 0\n",
    "\n",
    "#print(\"       Predicted       -          Actual\")\n",
    "for i in range(0, len(urdu_sen)):\n",
    "    print(\"Original : \",urdu_sen[i]) \n",
    "    print(\"Predicted : \" , y_sen[i])\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    #arg = (ref, hypothesis)\n",
    "    total_wer += wer(urdu_sen[i], y_sen[i])\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "avg_wer = total_wer / len(urdu_sen)\n",
    "    \n",
    "print(avg_wer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeedf956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4f1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
